{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ca24a8-1579-4e35-a55c-c362e335d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556f44b-3823-4c25-afb7-5e4c45152a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparity: 8.00 pixels\n",
      "Distance to the object: 5.30 meters\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance_to_object(camera_mtx, bbox_left, bbox_right):\n",
    "    \"\"\"\n",
    "    Calculate the distance to an object using bounding box coordinates from left and right images,\n",
    "    along with the camera calibration parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        bbox_left (list): Bounding box coordinates of left image (x_left, y_left, x_right, y_right)\n",
    "        bbox_right (list): Bounding box coordinates of right image (x_left, y_left, x_right, y_right)\n",
    "        camera_mtx (array): Camera intrinsics\n",
    "        \n",
    "    Returns:\n",
    "        float: Distance to the object (in meters)\n",
    "        float: Disparity between the left and right images (in pixels)\n",
    "    \"\"\"\n",
    "    baseline = 0.06\n",
    "\n",
    "    # Get the center of the bounding box in the left and right images\n",
    "    center_left = ((bbox_left[0] + bbox_left[2]) / 2, (bbox_left[1] + bbox_left[3]) / 2)\n",
    "    center_right = ((bbox_right[0] + bbox_right[2]) / 2, (bbox_right[1] + bbox_right[3]) / 2)\n",
    "\n",
    "    # Calculate disparity (horizontal pixel difference between the left and right image\n",
    "    x_left = center_left[0]\n",
    "    x_right = center_right[0]\n",
    "\n",
    "    disparity = abs(x_left - x_right)\n",
    "    \n",
    "    if disparity == 0:\n",
    "        return float('inf'), disparity  # If disparity is zero, the object is too far away or at the same location\n",
    "    \n",
    "    # Calculate the distance to the object using the formula\n",
    "    focal_length = camera_mtx[0, 0]\n",
    "    distance = (focal_length * baseline) / disparity\n",
    "    \n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Load images (grayscale)\n",
    "img_left = cv2.imread(\"/Users/dani/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/34759_final_project_rect/seq_01/image_02/data/000000.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img_right = cv2.imread(\"/Users/dani/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/34759_final_project_rect/seq_01/image_03/data/000000.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Example usage of the function\n",
    "left_bbox = (466.194319, 139.161762, 557.194320, 332.842544)  # Left image bounding box (left, top, right, bottom)\n",
    "right_bbox = (458.194319, 139.161762, 549.194320, 332.842544)  # Right image bounding box (left, top, right, bottom)\n",
    "\n",
    "# Camera parameters\n",
    "focal_length = 707.0493  # Example focal length in pixels (should match the calibration data)\n",
    "baseline = 0.06  # Example baseline in meters (distance between the cameras)\n",
    "\n",
    "# Call the function to calculate the distance and disparity\n",
    "distance, disparity = calculate_distance_to_object(left_bbox, right_bbox, focal_length, baseline, img_left, img_right)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Disparity: {disparity:.2f} pixels\")\n",
    "print(f\"Distance to the object: {distance:.2f} meters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274290da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_depth_map(camera_mtx, image_left, bbox_left, image_right, bbox_right):\n",
    "    \"\"\"\n",
    "    Create a depth map for an object using stereo images and bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        camera_mtx (numpy.ndarray): Camera intrinsic matrix (3x3).\n",
    "        image_left (numpy.ndarray): Left image (grayscale or color).\n",
    "        bbox_left (tuple): Bounding box in the left image (x_min, y_min, x_max, y_max).\n",
    "        image_right (numpy.ndarray): Right image (grayscale or color).\n",
    "        bbox_right (tuple): Bounding box in the right image (x_min, y_min, x_max, y_max).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Depth map (in meters) for the object within the bounding box.\n",
    "    \"\"\"\n",
    "    # Baseline in meters\n",
    "    baseline = 0.06  # Fixed at 6 cm\n",
    "\n",
    "    # Extract focal length from the camera intrinsic matrix\n",
    "    focal_length = camera_mtx[0, 0]  # Assuming fx (focal length in pixels)\n",
    "\n",
    "    # Convert images to grayscale if needed\n",
    "    if len(image_left.shape) == 3:\n",
    "        image_left = cv2.cvtColor(image_left, cv2.COLOR_BGR2GRAY)\n",
    "    if len(image_right.shape) == 3:\n",
    "        image_right = cv2.cvtColor(image_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Crop the regions of interest (ROIs) from the bounding boxes\n",
    "    x_min_left, y_min_left, x_max_left, y_max_left = bbox_left\n",
    "    x_min_right, y_min_right, x_max_right, y_max_right = bbox_right\n",
    "\n",
    "    roi_left = image_left[y_min_left:y_max_left, x_min_left:x_max_left]\n",
    "    roi_right = image_right[y_min_right:y_max_right, x_min_right:x_max_right]\n",
    "\n",
    "    # Stereo block matching using cv2.StereoSGBM_create\n",
    "    stereo = cv2.StereoSGBM_create(\n",
    "        minDisparity=0,  # Minimum possible disparity value. \n",
    "                        # Usually set to 0, but if the object is closer to the camera and disparities are expected to be large, increase this value.\n",
    "        \n",
    "        numDisparities=16 * 5,  # Maximum disparity minus minimum disparity.\n",
    "                                # Must be divisible by 16. Increasing this value allows matching objects farther away (lower disparity), but increases computation time.\n",
    "        \n",
    "        blockSize=9,  # Size of the matching block (odd number).\n",
    "                    # Larger values improve robustness to noise but may blur fine details. Smaller values provide better detail but are more sensitive to noise.\n",
    "        \n",
    "        P1=8 * 3 * 9 ** 2,  # Penalty for small changes in disparity (smoothness constraint).\n",
    "                            # Increase for smoother disparity maps, especially in regions with gradual depth changes. \n",
    "                            # Use lower values for scenes with high texture variation.\n",
    "        \n",
    "        P2=32 * 3 * 9 ** 2,  # Penalty for large changes in disparity (discontinuity constraint).\n",
    "                            # Higher values make the algorithm less sensitive to abrupt depth changes, improving smoothness but potentially losing sharp edges.\n",
    "        \n",
    "        disp12MaxDiff=1,  # Maximum allowed difference between left-right and right-left disparity computations.\n",
    "                        # Smaller values improve accuracy but can lead to gaps in the disparity map.\n",
    "        \n",
    "        uniquenessRatio=10,  # Margin by which the best match should be better than the second-best match (in percentage).\n",
    "                            # Lower values make the algorithm more permissive, increasing noise but capturing more detail. Higher values reduce noise but may miss details.\n",
    "        \n",
    "        speckleWindowSize=100,  # Maximum size of connected components considered as speckles (noise).\n",
    "                                # Increase to remove larger noise patches in disparity maps. Smaller values may leave speckles but preserve details.\n",
    "        \n",
    "        speckleRange=32,  # Maximum disparity variation within connected components (speckle filtering threshold).\n",
    "                        # Lower values remove speckles more aggressively, but this can also remove valid details. Increase to preserve more details.\n",
    "    )\n",
    "\n",
    "    # Compute disparity map for the cropped regions\n",
    "    disparity_map = stereo.compute(roi_left, roi_right).astype(np.float32) / 16.0\n",
    "\n",
    "    # Replace invalid disparities with NaN\n",
    "    disparity_map[disparity_map <= 0] = np.nan\n",
    "\n",
    "    # Calculate the depth map using the disparity map\n",
    "    depth_map = (baseline * focal_length) / disparity_map\n",
    "\n",
    "    return depth_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bd38c2-de78-4c05-b78f-b2877b502678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the left image\n",
    "left_image_path = r\"/Users/dani/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/34759_final_project_rect/seq_01/image_02/data/000000.png\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(left_image_path):\n",
    "    print(\"The file exists.\")\n",
    "else:\n",
    "    print(\"The file does not exist.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fe0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bearing(camera_mtx, bbox):\n",
    "    '''\n",
    "    Calculation of bearing from object relative to the camera\n",
    "    camera_mtx is an array with camera's intrinsics: fx, fy, cx, cy\n",
    "    object_coord are the coordinates of the object in the image frame: u, v\n",
    "    '''\n",
    "    fx = camera_mtx[0, 0]\n",
    "    cx = camera_mtx[0, 2]\n",
    "    x = (bbox[0] + bbox[2]) / 2\n",
    "    norm_x = (x - cx) / fx\n",
    "    bearing = np.arctan(norm_x)\n",
    "\n",
    "    bearing = (bearing + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "    return bearing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def calculate_rotation_y(camera_matrix, bbox, depth):\n",
    "    \"\"\"\n",
    "    Calculate the rotation y (yaw angle) of an object relative to the camera.\n",
    "    \n",
    "    Parameters:\n",
    "        camera_matrix (np.array): 3x3 intrinsic camera matrix.\n",
    "        depth (float): Depth (z-coordinate) of the object in the camera frame (meters).\n",
    "        image_center (tuple): (u, v) in pixel coordinates.\n",
    "        \n",
    "    Returns:\n",
    "        float: Rotation y (yaw angle) in radians, in range [-pi, pi].\n",
    "    \"\"\"\n",
    "    # Extract intrinsic parameters from the camera matrix\n",
    "    fx = camera_matrix[0, 0]\n",
    "    fy = camera_matrix[1, 1]\n",
    "    cx = camera_matrix[0, 2]\n",
    "    cy = camera_matrix[1, 2]\n",
    "    \n",
    "    # Calculate the center of the bounding box in image coordinates\n",
    "    u_center = (bbox[0] + bbox[2]) / 2\n",
    "    v_center = (bbox[1] + bbox[3]) / 2\n",
    "    \n",
    "    # Back-project the bounding box center to normalized image coordinates\n",
    "    x_norm = (u_center - cx) / fx\n",
    "    y_norm = (v_center - cy) / fy\n",
    "    \n",
    "    # Compute the 3D coordinates of the object's center in the camera frame\n",
    "    x_camera = x_norm * depth\n",
    "    z_camera = depth  # Depth is already given\n",
    "    \n",
    "    # Calculate the rotation_y (yaw angle) using arctan2\n",
    "    rotation_y = math.atan2(x_camera, z_camera)  # Yaw angle in radians\n",
    "    \n",
    "    # Ensure the result is in the range [-pi, pi]\n",
    "    rotation_y = (rotation_y + math.pi) % (2 * math.pi) - math.pi\n",
    "    \n",
    "    return rotation_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_to_world(camera_coords, R, t):\n",
    "    \"\"\"\n",
    "    Transform camera coordinates to world coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        camera_coords (np.array): 3D point in camera coordinates (x_c, y_c, z_c).\n",
    "        R (np.array): 3x3 rotation matrix (camera-to-world rotation).\n",
    "        t (np.array): 3x1 translation vector (camera-to-world translation).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 3D point in world coordinates (x_w, y_w, z_w).\n",
    "    \"\"\"\n",
    "    # Convert camera_coords to homogeneous coordinates\n",
    "    camera_coords_h = np.append(camera_coords, 1)  # Add 1 for homogeneous coordinates\n",
    "\n",
    "    # Construct extrinsic matrix T_cw\n",
    "    T_cw = np.eye(4)\n",
    "    T_cw[:3, :3] = R\n",
    "    T_cw[:3, 3] = t.flatten()\n",
    "\n",
    "    # Transform to world coordinates\n",
    "    world_coords_h = np.dot(T_cw, camera_coords_h)\n",
    "\n",
    "    # Convert back from homogeneous to 3D\n",
    "    world_coords = world_coords_h[:3]\n",
    "    \n",
    "    return world_coords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c843a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_height(bbox):\n",
    "    \"\"\"\n",
    "    Calculate the height of an object in the world coordinate system.\n",
    "\n",
    "    Args:\n",
    "        bbox (tuple): Bounding box coordinates in the image \n",
    "                      (x_min, y_min, x_max, y_max) format.\n",
    "\n",
    "    Returns:\n",
    "        float: Height of the object in the world coordinate system. \n",
    "               Returns NaN if height is negative.\n",
    "    \"\"\"\n",
    "    # Put the actual Rotation and Translation values here from camera calibration\n",
    "    R = np.eye(3)  # Example: Identity matrix (replace with calibrated rotation matrix)\n",
    "    T = np.array([1, 1, 1]).reshape(-1, 1)  # Example: Translation vector (replace with calibrated values)\n",
    "\n",
    "    # Extract top and bottom corners of the bounding box\n",
    "    top_corner = np.array([bbox[0], bbox[1]])\n",
    "    bottom_corner = np.array([bbox[2], bbox[3]])\n",
    "\n",
    "    # Transform the corners from camera to world coordinates\n",
    "    top = camera_to_world(top_corner, R, T)\n",
    "    bottom = camera_to_world(bottom_corner, R, T)\n",
    "\n",
    "    # Calculate the height (difference in the y-axis)\n",
    "    height = top[1] - bottom[1]\n",
    "\n",
    "    # Handle cases where height is invalid (negative)\n",
    "    if height < 0:\n",
    "        print(\"Negative height\")\n",
    "        return np.nan\n",
    "\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12773cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width(bbox):\n",
    "    \"\"\"\n",
    "    Calculate the width of an object in the world coordinate system.\n",
    "\n",
    "    Args:\n",
    "        bbox (tuple): Bounding box coordinates in the image \n",
    "                      (x_min, y_min, x_max, y_max) format.\n",
    "\n",
    "    Returns:\n",
    "        float: Width of the object in the world coordinate system.\n",
    "    \"\"\"\n",
    "    # Put the actual Rotation and Translation values here from camera calibration\n",
    "    R = np.eye(3)  # Example: Identity matrix (replace with calibrated rotation matrix)\n",
    "    T = np.array([1, 1, 1]).reshape(-1, 1)  # Example: Translation vector (replace with calibrated values)\n",
    "\n",
    "    # Extract top and bottom corners of the bounding box\n",
    "    top_corner = np.array([bbox[0], bbox[1]])\n",
    "    bottom_corner = np.array([bbox[2], bbox[3]])\n",
    "\n",
    "    # Transform the corners from camera to world coordinates\n",
    "    top = camera_to_world(top_corner, R, T)\n",
    "    bottom = camera_to_world(bottom_corner, R, T)\n",
    "\n",
    "    # Calculate the width (absolute difference in the x-axis)\n",
    "    width = abs(top[0] - bottom[0])\n",
    "\n",
    "    return width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50562b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(camera_mtx, image_left, bbox_left, image_right, bbox_right):\n",
    "    \"\"\"\n",
    "    Calculate the length of an object along the z-axis (depth).\n",
    "\n",
    "    Args:\n",
    "        camera_mtx (numpy.ndarray): Camera intrinsic matrix (3x3).\n",
    "        image_left (numpy.ndarray): Left stereo image (grayscale or color).\n",
    "        bbox_left (tuple): Bounding box in the left image (x_min, y_min, x_max, y_max).\n",
    "        image_right (numpy.ndarray): Right stereo image (grayscale or color).\n",
    "        bbox_right (tuple): Bounding box in the right image (x_min, y_min, x_max, y_max).\n",
    "\n",
    "    Returns:\n",
    "        float: Length of the object along the z-axis in meters.\n",
    "    \"\"\"\n",
    "    # Generate depth map for the object using stereo images and bounding boxes\n",
    "    object_depth = create_depth_map(camera_mtx, image_left, bbox_left, image_right, bbox_right)\n",
    "\n",
    "    # Filter out invalid depth values (e.g., 0 or NaN)\n",
    "    valid_depth = object_depth[object_depth > 0]\n",
    "\n",
    "    # Ensure there are valid depth values to calculate length\n",
    "    if valid_depth.size == 0:\n",
    "        print(\"No valid depth values found\")\n",
    "        return np.nan\n",
    "\n",
    "    # Get maximum and minimum depth values\n",
    "    max_depth = np.max(valid_depth)\n",
    "    min_depth = np.min(valid_depth)\n",
    "\n",
    "    # Calculate the length of the object along the z-axis (depth)\n",
    "    object_length = max_depth - min_depth\n",
    "\n",
    "    return object_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
